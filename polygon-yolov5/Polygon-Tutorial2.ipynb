{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltJaZ6GoYPfZ",
        "outputId": "9edcfd9f-effd-40fb-e449-69327cbb7604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Work/PolygonObjectDetection-main\n",
            "/content/gdrive/MyDrive/Work/PolygonObjectDetection-main/polygon-yolov5\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.62.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (1.8.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (2.0.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (2.7.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.1.5)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.42.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 22)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.1.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->-r requirements.txt (line 14)) (0.29.24)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        }
      ],
      "source": [
        "### For colab, run the following codes\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "## cd to your directory\n",
        "%cd /content/gdrive/MyDrive/Work/PolygonObjectDetection-main\n",
        "\n",
        "## cd to polygon-yolov5\n",
        "%cd polygon-yolov5\n",
        "\n",
        "## install requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/antoniomorais/Work/PolygonObjectDetection/polygon-yolov5\n"
          ]
        }
      ],
      "source": [
        "# LOCAL ONLY\n",
        "%cd /Users/antoniomorais/Work/PolygonObjectDetection/polygon-yolov5\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVJ_Wm9ny4Qd",
        "outputId": "ef0cbc4a-a724-4f75-9cb3-6eae8bd6937c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.20.3)\n",
            "Collecting opencv-python>=4.1.2\n",
            "  Downloading opencv_python-4.5.4.60-cp39-cp39-macosx_10_15_x86_64.whl (45.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.9 MB 26.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.7.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.10.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (4.62.3)\n",
            "Collecting shapely\n",
            "  Downloading Shapely-1.8.0-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (2.0.3)\n",
            "Collecting tensorboard>=2.4.1\n",
            "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 26.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.0 in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (1.3.4)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.9/site-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /opt/anaconda3/lib/python3.9/site-packages (from pycocotools->-r requirements.txt (line 14)) (58.0.4)\n",
            "Requirement already satisfied: cython>=0.27.3 in /opt/anaconda3/lib/python3.9/site-packages (from pycocotools->-r requirements.txt (line 14)) (0.29.24)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.26.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.37.0)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 17.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.42.0-cp39-cp39-macosx_10_10_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 18.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 12.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting protobuf>=3.6.0\n",
            "  Downloading protobuf-3.19.1-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 14.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 28.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 35.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 22)) (2021.3)\n",
            "Requirement already satisfied: six in /opt/anaconda3/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 38.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.6.0)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 17.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.0.4)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 37.3 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, thop, tensorboard, shapely, opencv-python\n",
            "Successfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-2.3.3 google-auth-oauthlib-0.4.6 grpcio-1.42.0 markdown-3.3.6 oauthlib-3.1.1 opencv-python-4.5.4.60 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 shapely-1.8.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 thop-0.0.31.post2005241907\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vX6QknwYPfc"
      },
      "source": [
        "## Polygon Tutorial 2\n",
        "Using data **segmentation** and module ***shapely*** to transform dataset to polygon boxes.\n",
        "<br> COCO dataset as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bYIvnF2LYPfd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pycocotools\n",
        "import shapely\n",
        "import shapely.geometry\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from pathlib import Path\n",
        "from itertools import repeat\n",
        "from tqdm import tqdm\n",
        "from pycocotools import coco, mask\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "oneD2twoD = lambda x: [(x[2*i], x[2*i+1]) for i in range(len(x)//2)]   # one D [x, y, x, y, x, y, ...] to [(x, y), (x, y), ...]\n",
        "catid_to_idx = {1: 0}\n",
        "\n",
        "\n",
        "def seg2poly(dataset_path='',\n",
        "             plot=True,):\n",
        "    \"\"\"\n",
        "        Transform segmentation to polygon labels (x1, y1, x2, y2, x3, y3, x4, y4)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Search for COCO json annotation files\n",
        "    f = []  # json files\n",
        "    p = Path(dataset_path)\n",
        "    assert p.is_dir(), \"'dataset_path' should be a valid path.\"\n",
        "    f += glob.glob(str(p / '**' / '*.json'), recursive=True)\n",
        "    assert f, f\"Error: no searched annotations files (.json) with {dataset_path}\"\n",
        "    \n",
        "    # Iterate through each json_file\n",
        "    for json_file in f:\n",
        "        coco_data = pycocotools.coco.COCO(json_file) # load coco data\n",
        "        \n",
        "        parent_path = Path(json_file).parent.parent\n",
        "        img_txt = [] # store searched image files\n",
        "        img_dir = parent_path / 'images'\n",
        "        # Get prefix name\n",
        "        for file in os.listdir(str(img_dir)):\n",
        "            if file in json_file:\n",
        "                prefix = file\n",
        "                break\n",
        "        \n",
        "        img_dir = img_dir / prefix\n",
        "        anno_dir = parent_path / 'labels' / prefix\n",
        "        if not os.path.exists(str(anno_dir)): os.mkdir(str(anno_dir))\n",
        "        \n",
        "        print(f'Begin transformation for {prefix}')\n",
        "        plot_now = 0\n",
        "        for img_i, img in enumerate(tqdm(coco_data.dataset['images'])):\n",
        "            \n",
        "            plot = plot and plot_now<3 # test the first three images that are not crowded\n",
        "            img_name = img_dir / img['file_name']\n",
        "            if img_name.exists():\n",
        "                anno_name = anno_dir / (os.path.splitext(img['file_name'])[0]+'.txt')\n",
        "                anno_txt = [] # store label information\n",
        "\n",
        "                if img['id'] not in coco_data.imgToAnns.keys(): continue\n",
        "                img_txt.append(str(img_name)) # store current image file\n",
        "\n",
        "                if plot: polygon_coords, segment_coords = [], [] # for plot\n",
        "\n",
        "                # iterate through each object\n",
        "                for object0 in coco_data.imgToAnns[img['id']]:\n",
        "\n",
        "                    # if not crowded, use segmentation\n",
        "                    if not object0['iscrowd']:\n",
        "                        # By tak-s: connect disjointed segmentations together\n",
        "                        segments = []\n",
        "                        for segment in object0['segmentation']:\n",
        "                            segments.extend(oneD2twoD(segment)+segments[:2])\n",
        "                        segments = [segments]\n",
        "                        \n",
        "                        if plot: \n",
        "                            polygon_coords.append([])\n",
        "                            segment_coords.append([])\n",
        "\n",
        "                    # if crowded, use bbox\n",
        "                    else: \n",
        "                        # x1, y1, x1, y2, x2, y2, x2, y1\n",
        "                        label = [catid_to_idx[object0['category_id']],\n",
        "                                 object0['bbox'][0], object0['bbox'][1], object0['bbox'][0], object0['bbox'][3],\n",
        "                                 object0['bbox'][2], object0['bbox'][3], object0['bbox'][2], object0['bbox'][0]] \n",
        "\n",
        "                        label = normalize_anchors(label, img['height'], img['width'])[0] # normalize xyxyxyxy\n",
        "                        anno_txt.append(label)\n",
        "                        continue\n",
        "\n",
        "                    # iterate through each segmentation\n",
        "                    for segment in segments:\n",
        "\n",
        "                        #using shapely::minimum_rotated_rectangle to convert segmentation\n",
        "                        multipoint = shapely.geometry.MultiPoint(segment)\n",
        "                        # polygon: class id, x1, y1, x2, y2, x3, y3, x4, y4 (unnormalized)\n",
        "                        try:\n",
        "                            label = [catid_to_idx[object0['category_id']],\n",
        "                                     *np.array(multipoint.minimum_rotated_rectangle.exterior.coords[:-1]).ravel().tolist()]\n",
        "                            label, label_pixel = normalize_anchors(label, img['height'], img['width']) # normalize xyxyxyxy\n",
        "                            anno_txt.append(label)\n",
        "                            if plot: \n",
        "                                polygon_coords[-1].append(np.vstack((label_pixel[1:].reshape(-1, 2), label_pixel[1:3])))\n",
        "                                segment_coords[-1].append(segment)\n",
        "                        except Exception as e:\n",
        "                            print('Warning: Ignore label, ', e)\n",
        "                if plot: \n",
        "                    polygon_plot_image(img_name, polygon_coords, segment_coords)\n",
        "                    plot_now += 1\n",
        "                np.savetxt(str(anno_name), np.array(anno_txt), fmt=[\"%i\"]+[\"%.6f\"]*8)\n",
        "        with open(str(parent_path/(prefix+'.txt')), 'w+') as f:\n",
        "            for img_i, img_name in enumerate(img_txt):\n",
        "                if img_i == len(img_txt)-1: f.write(img_name)\n",
        "                else: f.write(img_name+'\\n')\n",
        "\n",
        "\n",
        "def normalize_anchors(label, img_h, img_w):\n",
        "    \"\"\"\n",
        "        polygon\n",
        "        FROM class id, x1, y1, x2, y2, x3, y3, x4, y4 (unnormalized)\n",
        "        TO class id (unchanged), x1, y1, x2, y2, x3, y3, x4, y4 (normalized to [0, 1])\n",
        "    \"\"\"\n",
        "    label = np.array(label)\n",
        "    label_pixel = np.copy(label)\n",
        "    label[1::2] = label[1::2]/img_w\n",
        "    label[2::2] = label[2::2]/img_h\n",
        "    # Common out the following lines to enable: polygon corners can be out of images\n",
        "    # label[1::2] = label[1::2].clip(0., img_w)/img_w\n",
        "    # label[2::2] = label[2::2].clip(0., img_h)/img_h\n",
        "    # label_pixel[1::2] = label_pixel[1::2].clip(0., img_w)\n",
        "    # label_pixel[2::2] = label_pixel[2::2].clip(0., img_h)\n",
        "    return label, label_pixel\n",
        "        \n",
        "def polygon_plot_image(img_name, polygon_coords, segment_coords=None):\n",
        "    img = mpimg.imread(img_name)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img)\n",
        "    if segment_coords is not None:\n",
        "        for seg_coo in segment_coords:\n",
        "            for segment in seg_coo:\n",
        "                plt.plot(*list(zip(*segment)))\n",
        "    for poly_coo in polygon_coords:\n",
        "        for polygon in poly_coo:\n",
        "            plt.plot(*list(zip(*polygon)))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Pwezjj04YPff"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "def read_json_file(path_to_file):\n",
        "    with open(path_to_file, \"r\") as p:\n",
        "        return json.load(p)\n",
        "\n",
        "def read_labelme_anno(path_anno):\n",
        "    for dir_, _, files in os.walk(path_anno):\n",
        "        for file_name in files:\n",
        "            if not file_name[0] == '.':\n",
        "                rel_dir = os.path.relpath(dir_, path_anno)\n",
        "                rel_file = os.path.join(rel_dir, file_name)\n",
        "                _labelme_anno = read_json_file(rel_file)\n",
        "                print(_labelme_anno)\n",
        "    # for _path in os.listdir(path_anno):\n",
        "    #     _anno_rel_path = os.path.relpath(_path, start=\"/content/gdrive/MyDrive/Work/PolygonObjectDetection-main/data_rotation/labels/train\")\n",
        "    #     print(_anno_rel_path)\n",
        "    #     _labelme_anno = read_json_file(_anno_rel_path)\n",
        "    #     print(_labelme_anno)\n",
        "\n",
        "\n",
        "catidx = {\"tube\": 0}\n",
        "\n",
        "def convert_annos(labels_path):\n",
        "    # root dir is cwd in most cases \n",
        "    # dataset_path is the name of the dataset\n",
        "    # file structure:\n",
        "    #   - root\n",
        "    #       - dataset_path\n",
        "    #           - train\n",
        "    #               - images\n",
        "    #               - labels\n",
        "    #               - polygon_labels\n",
        "    #           - val\n",
        "    #               - images\n",
        "    #               - labels\n",
        "    #               - polygon_labels\n",
        "    # then you can manually change the name of the folders if you want\n",
        "    for dataset_folder in os.listdir(labels_path):\n",
        "        if not dataset_folder[0] == '.':\n",
        "            # train\n",
        "            polygon_anno_path = os.path.join(os.path.dirname(labels_path), \"polygon_labels\", dataset_folder)\n",
        "            if os.path.exists(polygon_anno_path):\n",
        "                shutil.rmtree(polygon_anno_path)\n",
        "            os.makedirs(polygon_anno_path)\n",
        "            json_dataset_folder = os.path.join(labels_path, dataset_folder)\n",
        "            for anno_file in os.listdir(json_dataset_folder):\n",
        "                if not anno_file[0] == '.':\n",
        "                    json_path = os.path.join(json_dataset_folder, anno_file)\n",
        "                    new_json_path = os.path.join(polygon_anno_path, os.path.splitext(anno_file)[0] + \".txt\")\n",
        "                    anno = read_json_file(json_path)\n",
        "                    annos_list = []\n",
        "                    for polygon in anno['shapes']:\n",
        "                        coordinates = []\n",
        "                        for point in polygon['points']:\n",
        "                            coordinates += point \n",
        "                        assert len(coordinates) == 8, \"Label does not have four points in \"+json_path\n",
        "                        cat = catidx[polygon['label']]\n",
        "                        labels = [cat, *coordinates]\n",
        "                        label, label_pixel = normalize_anchors(labels, anno[\"imageHeight\"], anno[\"imageWidth\"])\n",
        "                        annos_list.append(label)\n",
        "                    annos_array = np.array(annos_list)\n",
        "                    # write to new_json_path\n",
        "                    np.savetxt(str(new_json_path), annos_array, fmt=[\"%i\"]+[\"%.6f\"]*8)\n",
        "\n",
        "\n",
        "\n",
        "anno = convert_annos(\"/Users/antoniomorais/Work/PolygonObjectDetection/data_rotation/labels\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "8XTUgnTtYPfg",
        "outputId": "14d4d0e4-7cb9-46c3-ff52-58b9c5bcbaef"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-5d6631c8c0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pixel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1942\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2590\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "label, label_pixel = normalize_anchors(labels, 1942, 2590)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmloYqXq5I5Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Polygon-Tutorial2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
