{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import os\n",
    "import imageio\n",
    "from imgaug.augmentables.polys import Polygon, PolygonsOnImage\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "#Useful resources\n",
    "#augment polygons\n",
    "#https://nbviewer.org/github/aleju/imgaug-doc/blob/master/notebooks/B03%20-%20Augment%20Polygons.ipynb\n",
    "#multicore cpu augment\n",
    "#https://nbviewer.org/github/aleju/imgaug-doc/blob/master/notebooks/A03%20-%20Multicore%20Augmentation.ipynb\n",
    "\n",
    "# provide dataset path with following structure\n",
    "# data\n",
    "#   images\n",
    "#       train\n",
    "#           *.png\n",
    "#       val\n",
    "#           *.png\n",
    "#   labels\n",
    "#       train\n",
    "#           *.txt\n",
    "#       val\n",
    "#           *.txt\n",
    "\n",
    "# Where format of label txt files is classId x1 y1 x2 y2 x3 y3 x4 y4\n",
    "\n",
    "dataset_path = '../augmented_dataset'\n",
    "images_path = os.path.join(dataset_path, 'images')\n",
    "labels_path = os.path.join(dataset_path, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "def read_json_file(path_to_file: str):\n",
    "    with open(path_to_file, \"r\") as p:\n",
    "        return json.load(p)\n",
    "\n",
    "def read_labelme_anno(path_anno):\n",
    "    for dir_, _, files in os.walk(path_anno):\n",
    "        for file_name in files:\n",
    "            if not file_name[0] == '.':\n",
    "                rel_dir = os.path.relpath(dir_, path_anno)\n",
    "                rel_file = os.path.join(rel_dir, file_name)\n",
    "                _labelme_anno = read_json_file(rel_file)\n",
    "                print(_labelme_anno)\n",
    "    # for _path in os.listdir(path_anno):\n",
    "    #     _anno_rel_path = os.path.relpath(_path, start=\"/content/gdrive/MyDrive/Work/PolygonObjectDetection-main/data_rotation/labels/train\")\n",
    "    #     print(_anno_rel_path)\n",
    "    #     _labelme_anno = read_json_file(_anno_rel_path)\n",
    "    #     print(_labelme_anno)\n",
    "\n",
    "\n",
    "catidx = {\"tube\": 0}\n",
    "\n",
    "def convert_annos(labels_path):\n",
    "    # root dir is cwd in most cases \n",
    "    # dataset_path is the name of the dataset\n",
    "    # file structure:\n",
    "    #   - root\n",
    "    #       - dataset_path\n",
    "    #           - train\n",
    "    #               - images\n",
    "    #               - labels\n",
    "    #               - polygon_labels\n",
    "    #           - val\n",
    "    #               - images\n",
    "    #               - labels\n",
    "    #               - polygon_labels\n",
    "    # then you can manually change the name of the folders if you want\n",
    "    for dataset_folder in os.listdir(labels_path):\n",
    "        if not dataset_folder[0] == '.':\n",
    "            # train\n",
    "            polygon_anno_path = os.path.join(os.path.dirname(labels_path), \"polygon_labels\", dataset_folder)\n",
    "            if os.path.exists(polygon_anno_path):\n",
    "                shutil.rmtree(polygon_anno_path)\n",
    "            os.makedirs(polygon_anno_path)\n",
    "            json_dataset_folder = os.path.join(labels_path, dataset_folder)\n",
    "            for anno_file in os.listdir(json_dataset_folder):\n",
    "                if not anno_file[0] == '.':\n",
    "                    json_path = os.path.join(json_dataset_folder, anno_file)\n",
    "                    new_json_path = os.path.join(polygon_anno_path, os.path.splitext(anno_file)[0] + \".txt\")\n",
    "                    anno = read_json_file(json_path)\n",
    "                    annos_list = []\n",
    "                    for polygon in anno['shapes']:\n",
    "                        coordinates = []\n",
    "                        for point in polygon['points']:\n",
    "                            coordinates += point \n",
    "                        assert len(coordinates) == 8, \"Label does not have four points in \"+json_path\n",
    "                        cat = catidx[polygon['label']]\n",
    "                        labels = [cat, *coordinates]\n",
    "                        label, label_pixel = normalize_anchors(labels, anno[\"imageHeight\"], anno[\"imageWidth\"])\n",
    "                        annos_list.append(label)\n",
    "                    annos_array = np.array(annos_list)\n",
    "                    for an in annos_array:\n",
    "                        if len(an)==11:\n",
    "                            print(an)\n",
    "                    # write to new_json_path\n",
    "                    np.savetxt(str(new_json_path), annos_array, fmt=[\"%i\"]+[\"%.6f\"]*8)\n",
    "\n",
    "\n",
    "\n",
    "# anno = convert_annos(\"/Users/antoniomorais/Work/PolygonObjectDetection/data_rotation/labels\")\n",
    " \n",
    "\n",
    "def get_image_annotations(label_json: str):\n",
    "    # read json of labelme labels of an image, return list of polygons with classId\n",
    "    polygon_list = []\n",
    "    _labelme_anno = read_json_file(label_json)\n",
    "    for polygon in _labelme_anno['shapes']:\n",
    "        coordinates = []\n",
    "        for point in polygon['points']:\n",
    "            coordinates += point \n",
    "        assert len(coordinates) == 8, \"Label does not have four points in \"+label_json\n",
    "        cat = catidx[polygon['label']]\n",
    "        labels = [cat, *coordinates]\n",
    "        polygon_list.append(labels)\n",
    "    return polygon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to read polygons for a single image (first)\n",
    "# then we want to read every polygon of every image and store them in lists or something\n",
    "# [ [ polygon1 polygon2 polygon3 ... ], [ polygon1 polygon2 polygon3 ... ], ...]\n",
    "# this is the format for a polygon\n",
    "# in our case we need to read labelme annotations and read here\n",
    "\n",
    "# select set you want to augment here\n",
    "images_set_path = os.path.join(images_path, 'val')\n",
    "labels_set_path = os.path.join(labels_path, 'val')\n",
    "\n",
    "\n",
    "json_path = os.path.join(labels_set_path, \"Image__2021-12-13__11-26-09.json\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# image = imageio.imread(os.path.join(images_set_path, \"Image__2021-12-13__11-26-09.png\"))\n",
    "# ia.imshow(image)\n",
    "\n",
    "# _polygon_list = []\n",
    "# annotations_list = get_image_annotations(json_path)\n",
    "# for polygon in annotations_list:\n",
    "#     _, x1, y1, x2, y2, x3, y3, x4, y4 = polygon\n",
    "#     # right now only works for 4 cornered polygon\n",
    "#     _polygon = Polygon([\n",
    "#         (x1, y1), \n",
    "#         (x2, y2),  \n",
    "#         (x3, y3),  \n",
    "#         (x4, y4)\n",
    "#     ])\n",
    "#     _polygon_list.append(_polygon)\n",
    "    \n",
    "# image_polys = np.copy(image)\n",
    "# for _pol in _polygon_list:\n",
    "#     image_polys = _pol.draw_on_image(image_polys, alpha_face=0.2, size_points=7)\n",
    "# ia.imshow(image_polys)\n",
    "\n",
    "images_list = []\n",
    "polygons_list = []\n",
    "\n",
    "# this is for doing augmentation on an entire set\n",
    "for img in os.listdir(images_set_path):\n",
    "    # if hidden file\n",
    "    if img[0] == '.':\n",
    "        continue\n",
    "    img_path = os.path.join(images_set_path, img)\n",
    "    image = imageio.imread(img_path)\n",
    "    images_list.append((img_path, image))\n",
    "\n",
    "    img_name = os.path.splitext(img)[0]\n",
    "    json_path = os.path.join(labels_set_path, img_name + '.json')\n",
    "\n",
    "\n",
    "    _poly_list = []\n",
    "    annotations_list = get_image_annotations(json_path)\n",
    "    for polygon in annotations_list:\n",
    "        _, x1, y1, x2, y2, x3, y3, x4, y4 = polygon\n",
    "        # right now only works for 4 cornered polygon\n",
    "        _polygon = Polygon([\n",
    "            (x1, y1), \n",
    "            (x2, y2),  \n",
    "            (x3, y3),  \n",
    "            (x4, y4)\n",
    "        ])\n",
    "        _poly_list.append(_polygon)\n",
    "    polygons_list.append((json_path, _poly_list))\n",
    "\n",
    "#images_list[0] = (path, img)\n",
    "#polygons_list[0] = (path, [poly0, poly1, poly2, ...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_anchors(label, img_h, img_w):\n",
    "    \"\"\"\n",
    "        polygon\n",
    "        FROM class id, x1, y1, x2, y2, x3, y3, x4, y4 (unnormalized)\n",
    "        TO class id (unchanged), x1, y1, x2, y2, x3, y3, x4, y4 (normalized to [0, 1])\n",
    "    \"\"\"\n",
    "    label = np.array(label)\n",
    "    label_pixel = np.copy(label)\n",
    "    label[1::2] = label[1::2]/img_w\n",
    "    label[2::2] = label[2::2]/img_h\n",
    "    # Common out the following lines to enable: polygon corners can be out of images\n",
    "    # label[1::2] = label[1::2].clip(0., img_w)/img_w\n",
    "    # label[2::2] = label[2::2].clip(0., img_h)/img_h\n",
    "    # label_pixel[1::2] = label_pixel[1::2].clip(0., img_w)\n",
    "    # label_pixel[2::2] = label_pixel[2::2].clip(0., img_h)\n",
    "    return label, label_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(1942, 2590, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/92kqmmb53lv6td45442k08xh0000gn/T/ipykernel_87245/42506459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_json_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannos_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"%i\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"%.6f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0maugment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/wd/92kqmmb53lv6td45442k08xh0000gn/T/ipykernel_87245/42506459.py\u001b[0m in \u001b[0;36maugment_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mimageHeight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnChannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pixel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imageHeight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imageWidth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mannos_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: (1942, 2590, 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def augment_data(num_augmentations: int, path_augmentations: str):\n",
    "    \"\"\"\n",
    "    num_augmentations: number of augmented images to generate\n",
    "    path_augmentations: path to folder on which to put augmentations\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    while os.path.exists(path_augmentations):\n",
    "        count += 1 \n",
    "    if count > 0:\n",
    "        path_augmentations += str(count)\n",
    "        print(\"Path already exists. Creating images in \" + path_augmentations + \"instead\")\n",
    "    \n",
    "    augmented_images_folder_path = os.path.join(path_augmentations, \"images\")\n",
    "    augmented_labels_folder_path = os.path.join(path_augmentations, \"labels\")\n",
    "\n",
    "    os.makedirs(augmented_images_folder_path)\n",
    "    os.makedirs(augmented_labels_folder_path)\n",
    "    images_poly_aug = []\n",
    "    # TODO specify number of augmentations here\n",
    "\n",
    "    # TODO VERIFY THIS shuffle image and labels lists\n",
    "        \n",
    "    shuffled_list = list(zip(images_list, polygons_list))\n",
    "    random.shuffle(shuffled_list)\n",
    "\n",
    "    for idx, img_tuple, polygons_tuple in tqdm(enumerate(zip(*shuffled_list))):\n",
    "        if idx == num_augmentations:\n",
    "            return\n",
    "        img_path, img = img_tuple\n",
    "        polygons_path, polygons = polygons_tuple\n",
    "        _polygons_on_image = ia.PolygonsOnImage(polygons, shape=image.shape)\n",
    "\n",
    "        aug = iaa.Sequential([\n",
    "            iaa.AdditiveGaussianNoise(scale=10),\n",
    "            iaa.CoarseDropout(0.3, size_percent=0.005),\n",
    "            iaa.AddToHueAndSaturation((-50, 50)),\n",
    "            iaa.Affine(rotate=(-20, 20), translate_percent=(-0.3, 0.3), scale=(0.8, 1.2),\n",
    "                mode=[\"constant\", \"edge\"], cval=0),\n",
    "            iaa.Fliplr(0.5)\n",
    "            # TODO add augmentations here\n",
    "        ])\n",
    "\n",
    "        #TODO use parameter images= instead of image=\n",
    "        image_aug, psoi_aug = aug(image=img, polygons=_polygons_on_image)\n",
    "        # image_aug, psoi_aug = aug(image=image, polygons=_polygons_on_image)\n",
    "        # remove polygons that are outside of the image\n",
    "        clipped_psoi_aug = psoi_aug.remove_out_of_image(fully=True, partly=False).clip_out_of_image()\n",
    "        image_poly_aug = clipped_psoi_aug.draw_on_image(image_aug, alpha_face=0.2, size_points=10)\n",
    "        images_poly_aug.append(image_poly_aug)\n",
    "        \n",
    "        annos_list = []\n",
    "        for _pol in psoi_aug:\n",
    "            x1, y1 = _pol[0]\n",
    "            x2, y2 = _pol[1]\n",
    "            x3, y3 = _pol[2]\n",
    "            x4, y4 = _pol[3]\n",
    "            class_id = 0\n",
    "            #TODO only working for one label right now\n",
    "            cat = 0\n",
    "            coordinates = [x1, y1, x2, y2, x3, y3, x4, y4]\n",
    "            labels = [cat, *coordinates]\n",
    "            assert len(coordinates) == 8, \"Label does not have four points\"\n",
    "            labels = [cat, *coordinates]\n",
    "            augImageHeight, augImageWidth, _ = image_aug.shape\n",
    "            label, label_pixel = normalize_anchors(labels, augImageHeight, augImageWidth)\n",
    "            annos_list.append(label)\n",
    "        annos_array = np.array(annos_list)\n",
    "        imageio.imwrite(aug_image_path)\n",
    "        # write to new_json_path\n",
    "        np.savetxt(str(aug_label_path), annos_array, fmt=[\"%i\"]+[\"%.6f\"]*8)\n",
    "\n",
    "\n",
    "augment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
